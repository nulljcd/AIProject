{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializer\n",
    "used for initializing the hyper parameters before training\n",
    "- zero\n",
    "- one\n",
    "- random normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "  class Zero:\n",
    "    def calculateValue(self):\n",
    "      return 0\n",
    "      \n",
    "    def setValues(self, values):\n",
    "      for i in range(len(values)):\n",
    "        values[i] = self.calculateValue()\n",
    "\n",
    "  class One:\n",
    "    def calculateValue(self):\n",
    "      return 1\n",
    "\n",
    "    def setValues(self, values):\n",
    "      for i in range(len(values)):\n",
    "        values[i] = self.calculateValue()\n",
    "\n",
    "  class RandomNormalDistribution:\n",
    "    def __init__(self, mean, stddev):\n",
    "      self.mean = mean\n",
    "      self.stddev = stddev\n",
    "\n",
    "    def calculateValue(self):\n",
    "      return random.normalvariate(self.mean, self.stddev)\n",
    "\n",
    "    def setValues(self, values):\n",
    "      for i in range(len(values)):\n",
    "        values[i] = self.calculateValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation\n",
    "the activation function and derivative\n",
    "- linear\n",
    "- sigmoid\n",
    "- relu\n",
    "- leaky relu\n",
    "- tanh\n",
    "- silu\n",
    "- softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "  class Linear:\n",
    "    def calculate(self, inputs, index):\n",
    "      return inputs[index]\n",
    "      \n",
    "    def derivative(self, inputs, index):\n",
    "      return 1\n",
    "\n",
    "  class Sigmoid:\n",
    "    def calculate(self, inputs, index):\n",
    "      return 1 / (1 + math.exp(-inputs[index]))\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      a = self.calculate(inputs, index)\n",
    "      return a * (1 - a)\n",
    "\n",
    "  class ReLu:\n",
    "    def calculate(self, inputs, index):\n",
    "      return inputs[index] if inputs[index] > 0 else 0\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      return 1 if inputs[index] > 0 else 0\n",
    "\n",
    "  class LeakyReLu:\n",
    "    def __init__(self, alpha):\n",
    "      self.alpha = alpha\n",
    "\n",
    "    def calculate(self, inputs, index):\n",
    "      return inputs[index] if inputs[index] > 0 else inputs[index] * self.alpha\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      return 1 if inputs[index] > 0 else self.alpha\n",
    "      \n",
    "  class TanH:\n",
    "    def calculate(self, inputs, index):\n",
    "      e2 = math.exp(2 * inputs[index])\n",
    "      return (e2 - 1) / (e2 + 1)\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      t = self.calculate(inputs, index)\n",
    "      return 1 - t * t\n",
    "\n",
    "  class SiLu:\n",
    "    def calculate(self, inputs, index):\n",
    "      return inputs[index] / (1 + math.exp(-inputs[index]))\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      sig = 1 / (1 + math.exp(-inputs[index]))\n",
    "      return inputs[index] * sig * (1 - sig) + sig\n",
    "\n",
    "  class SoftMax:\n",
    "    def calculate(self, inputs, index):\n",
    "      expSum = 0\n",
    "      for inputIndex in range(len(inputs)):\n",
    "        expSum += math.exp(inputs[inputIndex])\n",
    "      return math.exp(inputs[index]) / expSum\n",
    "\n",
    "    def derivative(self, inputs, index):\n",
    "      expSum = 0\n",
    "      for inputIndex in range(len(inputs)):\n",
    "        expSum += Math.exp(inputs[inputIndex])\n",
    "      exp = Math.exp(inputs[index])\n",
    "      return (exp * expSum - exp * exp) / (expSum * expSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer\n",
    "layers for the neural network\n",
    "- linear\n",
    "- dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "  class Linear:\n",
    "    def __init__(self, numUnits):\n",
    "      self.numUnits = numUnits\n",
    "\n",
    "      self.values = None\n",
    "      self.numInputUnits = None\n",
    "\n",
    "      self.isTrainable = False\n",
    "      \n",
    "    def build(self, numInputUnits):\n",
    "      self.numInputUnits = numInputUnits\n",
    "      self.values = [0.0 for i in range(self.numUnits)]\n",
    "\n",
    "    def initialize(self):\n",
    "      pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      for neuronOutIndex in range(self.numUnits):\n",
    "        self.values[neuronOutIndex] = inputs[neuronOutIndex]\n",
    "      return self.values\n",
    "\n",
    "  class Dense:\n",
    "    def __init__(self, numUnits, weightInitializer, biasInitializer, activation):\n",
    "      self.numUnits = numUnits\n",
    "      self.weightInitializer = weightInitializer\n",
    "      self.biasInitializer = biasInitializer\n",
    "      self.activation = activation\n",
    "\n",
    "      self.values = None\n",
    "      self.numInputUnits = None\n",
    "      self.values = None\n",
    "      self.numWeights = None\n",
    "      self.numBiases = None\n",
    "      self.weights = None\n",
    "      self.biases = None\n",
    "\n",
    "      self.isTrainable = True\n",
    "\n",
    "    def build(self, numInputUnits):\n",
    "      self.numInputUnits = numInputUnits\n",
    "      self.values = [0.0 for i in range(self.numUnits)]\n",
    "      self.numWeights = self.numInputUnits * self.numUnits\n",
    "      self.numBiases = self.numUnits\n",
    "      self.weights = [0.0 for i in range(self.numWeights)]\n",
    "      self.biases = [0.0 for i in range(self.numBiases)]\n",
    "\n",
    "    def initialize(self):\n",
    "      self.weightInitializer.setValues(self.weights)\n",
    "      self.biasInitializer.setValues(self.biases)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      weightedInputs = [0.0 for i in range(self.numUnits)]\n",
    "      for neuronOutIndex in range(self.numUnits):\n",
    "        weightedInput = self.biases[neuronOutIndex]\n",
    "        for neuronInIndex in range(self.numInputUnits):\n",
    "          weightedInput += inputs[neuronInIndex] * self.weights[neuronInIndex + neuronOutIndex * self.numInputUnits]\n",
    "        weightedInputs[neuronOutIndex] = weightedInput\n",
    "      for neuronOutIndex in range(self.numUnits):\n",
    "        self.values[neuronOutIndex] = self.activation.calculate(weightedInputs, neuronOutIndex)\n",
    "      return self.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss\n",
    "calculates how much error the output of a neural network has to the expected output\n",
    "- mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "  class MeanSquaredError:\n",
    "    def calculate(self, predictedOutputs, expectedOutputs):\n",
    "      loss = 0\n",
    "      for outputIndex in range(len(predictedOutputs)):\n",
    "        error = predictedOutputs[outputIndex] - expectedOutputs[outputIndex]\n",
    "        loss += error * error\n",
    "      return loss * 0.5\n",
    "      \n",
    "    def derivative(self, predictedOutput, expectedOutput):\n",
    "      return predictedOutput - expectedOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model\n",
    "the neural network model\n",
    "- sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  class Sequential:\n",
    "    def __init__(self, layers):\n",
    "      self.layers = layers\n",
    "      \n",
    "      self.numLayers = len(self.layers)\n",
    "\n",
    "    def build(self):\n",
    "      self.layers[0].build(self.layers[0].numUnits)\n",
    "      for layerIndex in range(len(self.layers) - 1):\n",
    "        self.layers[layerIndex+1].build(self.layers[layerIndex].numUnits)\n",
    "        \n",
    "    def initialize(self):\n",
    "      for layerIndex in range(len(self.layers)):\n",
    "        self.layers[layerIndex].initialize()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      outputs = inputs;\n",
    "      for layerIndex in range(self.numLayers):\n",
    "        outputs = self.layers[layerIndex].forward(outputs);\n",
    "      return outputs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training system\n",
    "systems to train neural networks\n",
    "- deep genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSystem:\n",
    "  class DeepGeneticAlgorithm:\n",
    "    class MutateSystem:\n",
    "      class AddativeRandomNormalDistribution:\n",
    "        def __init__(self, mean, stddev):\n",
    "          self.mean = mean\n",
    "          self.stddev = stddev\n",
    "\n",
    "        def mutate(self, value):\n",
    "          return value + random.normalvariate(self.mean, self.stddev)\n",
    "    \n",
    "    def __init__(self, baseModel, numAgents, numParents, numElitist, weightMutateSystem, weightReplaceRate, biasMutateSystem, biasReplaceRate):\n",
    "      self.baseModel = baseModel\n",
    "      self.numAgents = numAgents\n",
    "      self.numParents = numParents\n",
    "      self.numElitist = numElitist\n",
    "      self.weightMutateSystem = weightMutateSystem\n",
    "      self.weightReplaceRate = weightReplaceRate\n",
    "      self.biasMutateSystem = biasMutateSystem\n",
    "      self.biasReplaceRate = biasReplaceRate\n",
    "\n",
    "      self.agents = None\n",
    "      self.agentLosses = None\n",
    "      self.fittestAgentIndexes = None\n",
    "\n",
    "    def build(self):\n",
    "      self.agents = [None for i in range(self.numAgents)]\n",
    "      self.agentLosses = [0.0 for i in range(self.numAgents)]\n",
    "      self.fittestAgentIndexes = [0 for i in range(self.numAgents)]\n",
    "\n",
    "      for agentIndex in range(self.numAgents):\n",
    "        self.agents[agentIndex] = copy.deepcopy(self.baseModel)\n",
    "        self.agents[agentIndex].build()\n",
    "        self.fittestAgentIndexes[agentIndex] = agentIndex\n",
    "      self.baseModel.build()\n",
    "\n",
    "    def initialize(self):\n",
    "      for agentIndex in range(self.numAgents):\n",
    "        self.agents[agentIndex].initialize()\n",
    "\n",
    "    def step(self):\n",
    "      def sortFunction(index):\n",
    "        return self.agentLosses[index]\n",
    "      self.fittestAgentIndexes.sort(key=sortFunction)\n",
    "\n",
    "      for layerIndex in range(self.baseModel.numLayers):\n",
    "        if not self.baseModel.layers[layerIndex].isTrainable:\n",
    "          continue\n",
    "\n",
    "        parentWeights = [0.0 for i in range(self.baseModel.layers[layerIndex].numWeights * self.numParents)]\n",
    "        parentBiases = [0.0 for i in range(self.baseModel.layers[layerIndex].numBiases * self.numParents)]\n",
    "        parentWeightIndexOffset = 0\n",
    "        parentBiasIndexOffset = 0\n",
    "\n",
    "        for parentIndex in range(self.numParents):\n",
    "          for weightIndex in range(self.baseModel.layers[layerIndex].numWeights):\n",
    "            parentWeights[weightIndex + parentWeightIndexOffset] = self.agents[self.fittestAgentIndexes[parentIndex]].layers[layerIndex].weights[weightIndex]\n",
    "          for biasIndex in range(self.baseModel.layers[layerIndex].numBiases):\n",
    "            parentBiases[biasIndex + parentBiasIndexOffset] = self.agents[self.fittestAgentIndexes[parentIndex]].layers[layerIndex].biases[biasIndex]\n",
    "          parentWeightIndexOffset += self.baseModel.layers[layerIndex].numWeights\n",
    "          parentBiasIndexOffset += self.baseModel.layers[layerIndex].numBiases\n",
    "        for agentIndex in range(self.numAgents - self.numElitist):\n",
    "          for weightIndex in range(self.baseModel.layers[layerIndex].numWeights):\n",
    "            agentLayerWeights = self.agents[self.fittestAgentIndexes[self.numAgents - agentIndex - 1]].layers[layerIndex].weights\n",
    "            if (random.random() < self.weightReplaceRate):\n",
    "              agentLayerWeights[weightIndex] = self.baseModel.layers[layerIndex].weightInitializer.calculateValue()\n",
    "            else:\n",
    "              agentLayerWeights[weightIndex] = parentWeights[weightIndex + int(random.random() * self.numParents) * self.baseModel.layers[layerIndex].numWeights]\n",
    "              agentLayerWeights[weightIndex] = self.weightMutateSystem.mutate(agentLayerWeights[weightIndex])\n",
    "          for biasIndex in range(self.baseModel.layers[layerIndex].numBiases):\n",
    "            agentLayerBiases = self.agents[self.fittestAgentIndexes[self.numAgents - agentIndex - 1]].layers[layerIndex].biases\n",
    "            if (random.random() < self.biasReplaceRate):\n",
    "              agentLayerBiases[biasIndex] = self.baseModel.layers[layerIndex].biasInitializer.calculateValue()\n",
    "            else:\n",
    "              agentLayerBiases[biasIndex] = parentBiases[biasIndex + int(random.random() * self.numParents) * self.baseModel.layers[layerIndex].numBiases]\n",
    "              agentLayerBiases[biasIndex] = self.biasMutateSystem.mutate(agentLayerBiases[biasIndex])\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test\n",
    "most complicated binary decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = Model.Sequential([\n",
    "  Layer.Linear(\n",
    "    2),\n",
    "  Layer.Dense(\n",
    "    6,\n",
    "    Initializer.RandomNormalDistribution(0, 1),\n",
    "    Initializer.RandomNormalDistribution(0, 1),\n",
    "    Activation.Sigmoid()),\n",
    "  Layer.Dense(\n",
    "    4,\n",
    "    Initializer.RandomNormalDistribution(0, 1),\n",
    "    Initializer.RandomNormalDistribution(0, 1),\n",
    "    Activation.SoftMax())])\n",
    "\n",
    "trainingSystem = TrainingSystem.DeepGeneticAlgorithm(\n",
    "  baseModel,\n",
    "  40, 4, 0,\n",
    "  TrainingSystem.DeepGeneticAlgorithm.MutateSystem.AddativeRandomNormalDistribution(0, 0.5), 0,\n",
    "  TrainingSystem.DeepGeneticAlgorithm.MutateSystem.AddativeRandomNormalDistribution(0, 0.5), 0)\n",
    "\n",
    "lossFunction = Loss.MeanSquaredError()\n",
    "\n",
    "trainingData = [\n",
    "  [[0, 0], [1, 0, 0, 0]],\n",
    "  [[1, 0], [0, 1, 0, 0]],\n",
    "  [[0, 1], [0, 0, 1, 0]],\n",
    "  [[1, 1], [0, 0, 0, 1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "  print('---- setting up')\n",
    "  trainingSystem.build()\n",
    "  trainingSystem.initialize()\n",
    "\n",
    "def train():\n",
    "  print('---- training')\n",
    "  for i in range(40):\n",
    "    for agentIndex in range(40):\n",
    "      totalLoss = 0\n",
    "      for sampleIndex in range(4):\n",
    "        outputs = trainingSystem.agents[agentIndex].forward(trainingData[sampleIndex][0])\n",
    "        totalLoss += lossFunction.calculate(outputs, trainingData[sampleIndex][1])\n",
    "      totalLoss /= 3\n",
    "      trainingSystem.agentLosses[agentIndex] = totalLoss\n",
    "    trainingSystem.step()\n",
    "    if i % 10 == 0:\n",
    "      print(f'  accuracy: {(1 - trainingSystem.agentLosses[trainingSystem.fittestAgentIndexes[0]]) * 100}%')\n",
    "\n",
    "def test():\n",
    "  print('---- testing')\n",
    "  model = trainingSystem.agents[trainingSystem.fittestAgentIndexes[0]]\n",
    "  for sampleIndex in range(4):\n",
    "    outputs = model.forward(trainingData[sampleIndex][0])\n",
    "    expectedOuputs = trainingData[sampleIndex][1]\n",
    "    loss = lossFunction.calculate(outputs, expectedOuputs)\n",
    "    print(f'-- case: {sampleIndex}')\n",
    "    print(f'  expected outputs: {expectedOuputs}')\n",
    "    print(f'  actual outputs: {outputs}')\n",
    "    print(f'  accuracy: {(1-loss) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "train()\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
